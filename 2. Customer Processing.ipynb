{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8577ca2b-c319-4a67-8858-55aec8a52fe6",
   "metadata": {},
   "source": [
    "This script is to be run after mail files have been returned from PeachTree.\n",
    "They will be stored in our FTP server.\n",
    "Unzip, change naming conventions as seen below, drag into Processing folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9e7a9-df54-4ea2-8085-7fcbe2afd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import pyodbc\n",
    "import os\n",
    "from pw import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b8a49-cdf5-4be4-bbbf-9e06757ce1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": cag_connection_string})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "from sqlalchemy.types import NVARCHAR\n",
    "cursor = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094a9b1-100a-445c-8168-22536424d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set brand name.\n",
    "brand = 'KP'\n",
    "## Set catalog run name.\n",
    "catalog = 'WN24'\n",
    "## Set the start/in home date.\n",
    "startdate = '01/08/2024'\n",
    "\n",
    "# Auto-setting brand name.\n",
    "if brand == \"CT\":\n",
    "    name = \"Connecting Threads (CT)\"\n",
    "elif brand == \"KP\":\n",
    "    name = \"Knit Picks (KP)\"\n",
    "elif brand == \"ST\":\n",
    "    name = \"Superior Threads (ST)\"\n",
    "elif brand == \"WC\":\n",
    "    name = \"We Crochet (WC)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb62aab-be15-4556-b8c4-7d4ada02e2fa",
   "metadata": {},
   "source": [
    "Drag mail files into the processing folder. \n",
    "You will need to change the title to match the syntax (brand Initials)_(catalog Code)_(INHOME/HOLDS/CA).\n",
    "E.g. KP_WN24_INHOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d26da8-b5bb-4d01-babb-f1b23cc264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inhome = pd.read_csv(r'./Processing/'+brand+'_'+catalog+'_INHOME.txt', sep = '|', names =['matchback','customerid','sourcecode','inhome'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f37cb-ac90-421e-b82a-055734a265d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "holds = pd.read_csv(r'./Processing/'+brand+'_'+catalog+'_HOLDS.csv', dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280d3d5-f392-49c5-863f-2f2264742e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada = pd.read_csv(r'./Processing/'+brand+'_'+catalog+'_CA.csv', dtype = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801123d-2dbc-418d-bb2c-e0c7dedfdd47",
   "metadata": {},
   "source": [
    "Insert imported files into CAGMAIN.DATA_IMPORTS for long term storage.\n",
    "The sprocs in place for processing blend new and old, no need to import twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed935d-73f6-4ddc-9e56-8937e03df2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inhome.to_sql(brand+'_'+catalog+'_INHOME', engine, if_exists='replace', index=False, dtype={col_name: NVARCHAR for col_name in inhome})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a7ad5-60f8-46cb-9a08-42a1ba3282d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "holds.to_sql(brand+'_'+catalog+'_HOLDS', engine, if_exists='replace', index=False, dtype={col_name: NVARCHAR for col_name in holds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c24ff-f7cf-44c7-8fa5-489a308fa5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada.to_sql(brand+'_'+catalog+'_CA', engine, if_exists='replace', index=False, dtype={col_name: NVARCHAR for col_name in canada})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f762f52-942b-43ba-bc46-7e3c52444a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": pna_connection_string})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "from sqlalchemy.types import NVARCHAR\n",
    "cursor = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078a4ed-05bf-4a71-aa55-0d6e4de035ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inhome_query = (\n",
    "\"SELECT \"\n",
    "\"CAST(b.id AS INT) as internalid,  \"\n",
    "\"a.customerid, \"\n",
    "\"a.matchback, \"\n",
    "\"'\"+catalog+\"' as catalog, \"\n",
    "\"a.sourcecode, \"\n",
    "\"'\"+startdate+\"' as inhome, \" \n",
    "\"'\"+name+\"' as brand \"\n",
    "\"FROM \"+cag_server+\".\"+cag_db+\".dbo.\"+brand+\"_\"+catalog+\"_INHOME A \"\n",
    "\"INNER JOIN NETSUITE.ns.Customer B \"\n",
    "\"ON A.customerid = B.entityid \"\n",
    "\"WHERE a.customerid <> 'employee' \"\n",
    "\"AND a.sourcecode <> 'employee' \"\n",
    ")\n",
    "\n",
    "inhome_df = pd.read_sql_query(inhome_query, engine)\n",
    "\n",
    "inhome_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441fc83d-6876-458b-9eb4-129e08a968a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "holds_query = (\n",
    "\"SELECT \"\n",
    "\"CAST(b.id AS INT) as internalid,  \"\n",
    "\"a.customerid, \"\n",
    "\"a.matchback, \"\n",
    "\"'\"+catalog+\"' as catalog, \"\n",
    "\"a.sourcecode, \"\n",
    "\"'\"+startdate+\"' as inhome, \" \n",
    "\"'\"+name+\"' as brand \"\n",
    "\"FROM \"+cag_server+\".\"+cag_db+\".dbo.\"+brand+\"_\"+catalog+\"_HOLDS A \"\n",
    "\"INNER JOIN NETSUITE.ns.Customer B \"\n",
    "\"ON A.customerid = B.entityid \"\n",
    "\"WHERE a.customerid <> 'employee' \"\n",
    "\"AND a.sourcecode <> 'employee' \"\n",
    ")\n",
    "\n",
    "holds_df = pd.read_sql_query(holds_query, engine)\n",
    "\n",
    "holds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ef509-6c00-4a4c-873e-5801e3bc587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_query = (\n",
    "\"SELECT \"\n",
    "\"CAST(b.id AS INT) as internalid,  \"\n",
    "\"a.customerid, \"\n",
    "\"a.matchback, \"\n",
    "\"'\"+catalog+\"' as catalog, \"\n",
    "\"a.sourcecode, \"\n",
    "\"'\"+startdate+\"' as inhome, \" \n",
    "\"'\"+name+\"' as brand \"\n",
    "\"FROM \"+cag_server+\".\"+cag_db+\".dbo.\"+brand+\"_\"+catalog+\"_CA A \"\n",
    "\"INNER JOIN NETSUITE.ns.Customer B \"\n",
    "\"ON A.customerid = B.entityid \"\n",
    "\"WHERE a.customerid <> 'employee' \"\n",
    "\"AND a.sourcecode <> 'employee' \"\n",
    ")\n",
    "\n",
    "canada_df = pd.read_sql_query(canada_query, engine)\n",
    "\n",
    "canada_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd585e42-126c-4c80-b638-b6871aed8d36",
   "metadata": {},
   "source": [
    "Now union all three dataframes.\n",
    "We are creating a main table, adding a unique external id, and breaking into multiple csvs to upload into Netsuite.\n",
    "We currently don't have the option to programatically insert these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82313d92-2844-4b24-a8da-c27525b410cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union all data frames together.\n",
    "df = pd.concat([inhome_df, holds_df, canada_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979657c-91f6-4984-99f6-618aec7c04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique external id with 6 digit places, depending on file size.\n",
    "total_rows = len(df)\n",
    "counts = [str(i).zfill(6) for i in range(1, total_rows + 1)]\n",
    "# Create External ID column.\n",
    "df['externalid'] = brand + '-' + catalog + '-' + pd.Series(counts, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7dbe49-be52-46dd-a92a-ec193f7de2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size and naming convention\n",
    "chunk_size = 24999\n",
    "naming_convention = '_V'\n",
    "\n",
    "# Calculate the number of chunks needed\n",
    "num_chunks = (len(df) // chunk_size) + 1\n",
    "\n",
    "# Folder Path\n",
    "folder_path = os.path.join('Exports', brand, catalog, 'Source Codes')\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Export the data frame into multiple CSV files\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    chunk = df.iloc[start:end]\n",
    "    filename = os.path.join(folder_path, f'{brand}_{catalog}_{naming_convention}{i + 1}.csv')\n",
    "    chunk.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
